\documentclass[12pt,english]{article}
\usepackage[authoryear]{natbib}

\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

\begin{document}

\section{Outline}
\begin{itemize}
\item Introduction
    \begin{itemize}
    \item There is a widespread problem with diversity in the tech industry. One problem that is emerging from this trend is in artificial intelligence. There have been multiple reports of AIs taking on biases that humans have. A widely-known example is the Microsoft AI called Tay. Tay was an AI built for Twitter to engage in "playful" conversation with Twitter users who interact with it. It soon starting tweeting racist and harmful content which was "learned" through conversations and content on Twitter. It made it apparent that AI takes on human biases. Tay was corrupted through the public data the AI used to train. However, biases in AI are easily created through the code itself.
    \item Another problem is that popular datasets themselves also contain biases. Examples will be added here.
    \item Main point 3
    \end{itemize}
\item Lit Review
    \begin{itemize}
    \item Sentiment Analysis and AI is heavily discussed in "Semantics derived automatically from language corpora contain human-like biases" by Aylin Caliskan, Joanna J. Bryson, and Arvind Narayanan.
    \item Main point 2
    \item Main point 3
    \end{itemize}
\item Data
    \begin{itemize}
    \item The data used in this project is open-source big data. I have not decided what exactly which one to use, but ones that I am considering are a Kaggle data set, the IMBD-WIKI data set, the Twitter100k data set, & the Google Open Images data set.
    \item Main point 2
    \item Main point 3
    \end{itemize}
\item Empirical Methods
    \begin{itemize}
    \item I am currently in the process of redesigning my project based on feedback from my data science boss at Sonic.
    \item Main point 2
    \item Main point 3
    \end{itemize}
\item (Anticipated) findings
    \begin{itemize}
    \item The aim for this project is to either show how AI can be bias based off of popular open source code and open source training data sets. Another path might be discussing how to fix biases in AI, specific to this project.
    \item Main point 2
    \item Main point 3
    \end{itemize}
\item Conclusion
    \begin{itemize}
    \item Conclusion will depend on the finding after redesigning this project. There is an extensive amount of research and coverage on bias AIs and not anything that claims the opposite, so the conclusion is likely predictable.
    \item Main point 2
    \item Main point 3
    \end{itemize}
\end{itemize}

\bibliographystyle{jpe}
\nocite{*}
\bibliography{MWE.bib}

\end{document}
